{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2097406,"sourceType":"datasetVersion","datasetId":1257880},{"sourceId":7639129,"sourceType":"datasetVersion","datasetId":4452056}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.transforms import v2\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom PIL import Image\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nimport timm\nimport random\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:02.929656Z","iopub.execute_input":"2024-02-18T09:25:02.930210Z","iopub.status.idle":"2024-02-18T09:25:09.955735Z","shell.execute_reply.started":"2024-02-18T09:25:02.930182Z","shell.execute_reply":"2024-02-18T09:25:09.954646Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def import_dataset(clip_limit=None,tilegridsize=None,Clahe = False):\n    \n    if Clahe:\n        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tilegridsize)\n    \n    train_dict = {}\n    val_dict = {}\n    test_dict = {}\n    \n    train_path = \"/kaggle/input/knee-osteoarthritis-dataset-with-severity/train/\"\n    val_path = \"/kaggle/input/knee-osteoarthritis-dataset-with-severity/val/\"\n    test_path = \"/kaggle/input/knee-osteoarthritis-dataset-with-severity/test/\"\n    \n    for label in os.listdir(train_path):\n        train_dict[int(label)] = os.listdir(train_path + label)\n    for label in os.listdir(test_path):\n        test_dict[int(label)] = os.listdir(test_path + label)\n    for label in os.listdir(val_path):\n        val_dict[int(label)] = os.listdir(val_path + label)\n        \n    train_images = {}\n    val_images = {}\n    test_images = {}\n    \n    for keys in train_dict.keys():  \n        normal_train_images = [np.array(Image.open(train_path + str(keys) + \"/\" + images)) for images in train_dict[keys]]\n        normal_test_images = [np.array(Image.open(test_path + str(keys) + \"/\" + images)) for images in test_dict[keys]]\n        normal_val_images = [np.array(Image.open(val_path + str(keys) + \"/\" + images)) for images in val_dict[keys]]\n        \n        if Clahe:\n            clahe_train_images = [clahe.apply(np.array(Image.open(train_path + str(keys) + \"/\" + images))) for images in train_dict[keys]]\n            clahe_test_images = [clahe.apply(np.array(Image.open(test_path + str(keys) + \"/\" + images))) for images in test_dict[keys]]\n            clahe_val_images = [clahe.apply(np.array(Image.open(val_path + str(keys) + \"/\" + images))) for images in val_dict[keys]]\n            \n            train_images[keys] =  clahe_train_images\n            test_images[keys] =  clahe_test_images\n            val_images[keys] =  clahe_val_images\n            \n        else:\n            train_images[keys] = normal_train_images\n            test_images[keys] = normal_test_images\n            val_images[keys] = normal_val_images \n            \n            \n    return train_images,test_images,val_images","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:10.964068Z","iopub.execute_input":"2024-02-18T09:25:10.964430Z","iopub.status.idle":"2024-02-18T09:25:10.977442Z","shell.execute_reply.started":"2024-02-18T09:25:10.964401Z","shell.execute_reply":"2024-02-18T09:25:10.976307Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def create_tensors(train_images,test_images,val_images):\n    \n    trlabel0 = [0 for i in range(len(train_images[0]))]\n    trlabel1 = [1 for i in range(len(train_images[1]))]\n    trlabel2 = [2 for i in range(len(train_images[2]))]\n    trlabel3 = [3 for i in range(len(train_images[3]))]\n    trlabel4 = [4 for i in range(len(train_images[4]))]\n    \n    tslabel0 = [0 for i in range(len(test_images[0]))]\n    tslabel1 = [1 for i in range(len(test_images[1]))]\n    tslabel2 = [2 for i in range(len(test_images[2]))]\n    tslabel3 = [3 for i in range(len(test_images[3]))]\n    tslabel4 = [4 for i in range(len(test_images[4]))]\n    \n    vlabel0 = [0 for i in range(len(val_images[0]))]\n    vlabel1 = [1 for i in range(len(val_images[1]))]\n    vlabel2 = [2 for i in range(len(val_images[2]))]\n    vlabel3 = [3 for i in range(len(val_images[3]))]\n    vlabel4 = [4 for i in range(len(val_images[4]))]\n    \n    \n    training_image  = torch.tensor(torch.cat((torch.tensor(train_images[0]),torch.tensor(train_images[1]),torch.tensor(train_images[2]),torch.tensor(train_images[3]),torch.tensor(train_images[4])),0),dtype = torch.float32)\n    training_labels = torch.tensor(torch.cat((torch.tensor(trlabel0),torch.tensor(trlabel1),torch.tensor(trlabel2),torch.tensor(trlabel3),torch.tensor(trlabel4)),0))\n    training_image = training_image.view(training_image.shape[0],1,224,224)\n    \n    testing_image  = torch.tensor(torch.cat((torch.tensor(test_images[0]),torch.tensor(test_images[1]),torch.tensor(test_images[2]),torch.tensor(test_images[3]),torch.tensor(test_images[4])),0),dtype = torch.float32)\n    testing_labels = torch.tensor(torch.cat((torch.tensor(tslabel0),torch.tensor(tslabel1),torch.tensor(tslabel2),torch.tensor(tslabel3),torch.tensor(tslabel4)),0))\n    testing_image = testing_image.view(testing_image.shape[0],1,224,224)\n    \n    val_image  = torch.tensor(torch.cat((torch.tensor(val_images[0]),torch.tensor(val_images[1]),torch.tensor(val_images[2]),torch.tensor(val_images[3]),torch.tensor(val_images[4])),0),dtype = torch.float32)\n    val_labels = torch.tensor(torch.cat((torch.tensor(vlabel0),torch.tensor(vlabel1),torch.tensor(vlabel2),torch.tensor(vlabel3),torch.tensor(vlabel4)),0))\n    val_image = val_image.view(val_image.shape[0],1,224,224)\n    \n    return training_image,training_labels,testing_image,testing_labels,val_image,val_labels","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:14.994472Z","iopub.execute_input":"2024-02-18T09:25:14.994844Z","iopub.status.idle":"2024-02-18T09:25:15.011948Z","shell.execute_reply.started":"2024-02-18T09:25:14.994811Z","shell.execute_reply":"2024-02-18T09:25:15.011098Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_dataset(training_image,training_labels,testing_image,testing_labels,val_image,val_labels,batch_size = 4):\n    train_dataset = TensorDataset(training_image,training_labels)\n    val_dataset = TensorDataset(val_image,val_labels)\n    test_dataset = TensorDataset(testing_image,testing_labels)\n    \n    train_loader = DataLoader(train_dataset,shuffle= True , batch_size = batch_size)\n    val_loader = DataLoader(val_dataset,shuffle = True , batch_size = batch_size)\n    test_loader = DataLoader(test_dataset,shuffle = True, batch_size = batch_size)\n    \n    return train_loader,test_loader,val_loader","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:17.929014Z","iopub.execute_input":"2024-02-18T09:25:17.929393Z","iopub.status.idle":"2024-02-18T09:25:17.935768Z","shell.execute_reply.started":"2024-02-18T09:25:17.929361Z","shell.execute_reply":"2024-02-18T09:25:17.934652Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"original_model= torchvision.models.vgg16_bn(pretrained = True)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:21.208849Z","iopub.execute_input":"2024-02-18T09:25:21.209447Z","iopub.status.idle":"2024-02-18T09:25:27.671530Z","shell.execute_reply.started":"2024-02-18T09:25:21.209418Z","shell.execute_reply":"2024-02-18T09:25:27.670503Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n100%|██████████| 528M/528M [00:03<00:00, 144MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"original_model.features[0] = nn.Conv2d(1,64,kernel_size = (3,3),stride = 1,padding = 1)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:30.088954Z","iopub.execute_input":"2024-02-18T09:25:30.089772Z","iopub.status.idle":"2024-02-18T09:25:30.094865Z","shell.execute_reply.started":"2024-02-18T09:25:30.089743Z","shell.execute_reply":"2024-02-18T09:25:30.093865Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class NewModel(nn.Module):\n    def __init__(self,model):\n        super(NewModel,self).__init__()\n        features = list(model.features.children())\n                \n        self.features = nn.Sequential(\n                        *features,\n                        )\n        \n        self.avgpool = nn.AvgPool2d(2)\n        \n        self.classifier = nn.Sequential(\n                            nn.Linear(512*3,512),\n                            nn.BatchNorm1d(512),\n                            nn.ReLU(inplace = True),\n                            nn.Dropout(p = 0.3,inplace = False),\n                            nn.Linear(512,5),\n                            )\n        \n            \n    def forward(self,x):\n            x = self.features(x)\n            x = self.avgpool(x)\n            x = x.view(x.shape[0],-1)\n            \n            x = self.classifier(x)\n            \n            return x","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:39:59.809875Z","iopub.execute_input":"2024-02-18T09:39:59.810238Z","iopub.status.idle":"2024-02-18T09:39:59.818297Z","shell.execute_reply.started":"2024-02-18T09:39:59.810210Z","shell.execute_reply":"2024-02-18T09:39:59.817339Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def create_model(original_model,no_of_layers =22):\n    model = NewModel(original_model)\n\n    filtered_state_dict = {k: v for k, v in original_model.state_dict().items() if k in model.state_dict() and v.shape == model.state_dict()[k].shape}\n    \n    model.load_state_dict(filtered_state_dict, strict=False)\n    \n    for i, params in enumerate(model.parameters()):\n        if i < no_of_layers:\n            params.requires_grad = False\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:33.660843Z","iopub.execute_input":"2024-02-18T09:25:33.661173Z","iopub.status.idle":"2024-02-18T09:25:33.667370Z","shell.execute_reply.started":"2024-02-18T09:25:33.661148Z","shell.execute_reply":"2024-02-18T09:25:33.666353Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def params(nmmodel,learning_rate = 0.0001):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(nmmodel.parameters(),lr = learning_rate)\n    \n    return nmmodel,criterion,optimizer","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:35.428873Z","iopub.execute_input":"2024-02-18T09:25:35.429210Z","iopub.status.idle":"2024-02-18T09:25:35.434008Z","shell.execute_reply.started":"2024-02-18T09:25:35.429185Z","shell.execute_reply":"2024-02-18T09:25:35.433098Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def training(train_loader,val_loader,epochs = 10):\n    training_loss = 0.0\n    training_accuracy = 0\n    validation_accuracy = 0\n    device = 'cuda'\n    for epoch in range(epochs):\n        n_samples_train = 0\n        n_samples_val = 0\n        for i, (images, labels) in enumerate(train_loader):\n\n            images = images.to(device)\n            labels = labels.to(device)\n            output = model(images)\n            loss = criterion(output, labels)\n            n_samples_train += labels.size(0)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            _, predicted = torch.max(output.data, 1)\n            training_accuracy += (predicted == labels).sum().item()\n\n            if (i + 1) % 512 == 0:\n                print(f'Training - Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {loss.item():.4f}')\n\n        print(f'Training Accuracy - Epoch: {epoch + 1}: {training_accuracy * 100 / n_samples_train:.2f}%')\n        training_accuracy = 0\n\n        with torch.no_grad():\n            for i, (val_images, val_labels) in enumerate(val_loader):\n\n                val_images = val_images.to(device)\n                val_labels = val_labels.to(device)\n                val_output = model(val_images)\n                _, val_predicted = torch.max(val_output.data, 1)\n                validation_accuracy += (val_predicted == val_labels).sum().item()\n                n_samples_val += val_labels.size(0)\n\n        print(f'Validation Accuracy - Epoch: {epoch + 1}: {validation_accuracy * 100 / n_samples_val:.2f}%')\n        validation_accuracy = 0","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:37.349639Z","iopub.execute_input":"2024-02-18T09:25:37.349966Z","iopub.status.idle":"2024-02-18T09:25:37.360310Z","shell.execute_reply.started":"2024-02-18T09:25:37.349942Z","shell.execute_reply":"2024-02-18T09:25:37.359300Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def testing(test_loader):\n    device = 'cuda'\n    with torch.no_grad():\n        n_correct = 0\n        n_samples = 0\n        test_loss = 0.0\n        test_accuracy = 0\n        for i,(images, labels) in enumerate(test_loader):\n\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs.data,labels)\n            _, predicted = torch.max(outputs.data, 1)\n            n_samples += labels.size(0)\n            n_correct += (predicted == labels).sum().item()\n            test_accuracy = n_correct\n            test_loss = loss.item()\n            if((i+1)%50 == 0):\n\n                test_accuracy = 0\n                test_loss = 0\n        acc = 100.0 * n_correct / n_samples\n        print(f'Accuracy of the network on the {n_samples} test images:{acc:.4f}%')\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:25:39.058884Z","iopub.execute_input":"2024-02-18T09:25:39.059211Z","iopub.status.idle":"2024-02-18T09:25:39.066885Z","shell.execute_reply.started":"2024-02-18T09:25:39.059188Z","shell.execute_reply":"2024-02-18T09:25:39.065886Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_images,test_images,val_images = import_dataset()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:26:02.771659Z","iopub.execute_input":"2024-02-18T09:26:02.772448Z","iopub.status.idle":"2024-02-18T09:27:16.784443Z","shell.execute_reply.started":"2024-02-18T09:26:02.772419Z","shell.execute_reply":"2024-02-18T09:27:16.783643Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_image,training_labels,testing_image,testing_labels,val_image,val_labels = create_tensors(train_images,test_images,val_images)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:27:16.785928Z","iopub.execute_input":"2024-02-18T09:27:16.786217Z","iopub.status.idle":"2024-02-18T09:29:11.675753Z","shell.execute_reply.started":"2024-02-18T09:27:16.786194Z","shell.execute_reply":"2024-02-18T09:29:11.674735Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tr_image = training_image[:,:,65:180,:]\nts_image = testing_image[:,:,65:180,:]\nv_image = val_image[:,:,65:180,:]","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:37:09.670341Z","iopub.execute_input":"2024-02-18T09:37:09.671002Z","iopub.status.idle":"2024-02-18T09:37:09.676047Z","shell.execute_reply.started":"2024-02-18T09:37:09.670971Z","shell.execute_reply":"2024-02-18T09:37:09.675024Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"train_loader,test_loader,val_loader = create_dataset(tr_image,training_labels,ts_image,testing_labels,v_image,val_labels,batch_size = 4)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:37:33.629303Z","iopub.execute_input":"2024-02-18T09:37:33.629670Z","iopub.status.idle":"2024-02-18T09:37:33.634520Z","shell.execute_reply.started":"2024-02-18T09:37:33.629642Z","shell.execute_reply":"2024-02-18T09:37:33.633650Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"model = create_model(original_model,no_of_layers = 22)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:40:04.904351Z","iopub.execute_input":"2024-02-18T09:40:04.905055Z","iopub.status.idle":"2024-02-18T09:40:04.996282Z","shell.execute_reply.started":"2024-02-18T09:40:04.905026Z","shell.execute_reply":"2024-02-18T09:40:04.995611Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"model.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:40:06.609470Z","iopub.execute_input":"2024-02-18T09:40:06.610138Z","iopub.status.idle":"2024-02-18T09:40:06.619632Z","shell.execute_reply.started":"2024-02-18T09:40:06.610108Z","shell.execute_reply":"2024-02-18T09:40:06.618767Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"NewModel(\n  (features): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (26): ReLU(inplace=True)\n    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (36): ReLU(inplace=True)\n    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (39): ReLU(inplace=True)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (classifier): Sequential(\n    (0): Linear(in_features=1536, out_features=512, bias=True)\n    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.3, inplace=False)\n    (4): Linear(in_features=512, out_features=5, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model,criterion,optimizer = params(model)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:40:10.999022Z","iopub.execute_input":"2024-02-18T09:40:10.999731Z","iopub.status.idle":"2024-02-18T09:40:11.004422Z","shell.execute_reply.started":"2024-02-18T09:40:10.999700Z","shell.execute_reply":"2024-02-18T09:40:11.003572Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"training(train_loader,val_loader,epochs = 8)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:40:13.919123Z","iopub.execute_input":"2024-02-18T09:40:13.919878Z","iopub.status.idle":"2024-02-18T09:43:53.066789Z","shell.execute_reply.started":"2024-02-18T09:40:13.919847Z","shell.execute_reply":"2024-02-18T09:43:53.065863Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Training - Epoch: 1, Batch: 512, Loss: 0.9294\nTraining - Epoch: 1, Batch: 1024, Loss: 1.3976\nTraining Accuracy - Epoch: 1: 46.04%\nValidation Accuracy - Epoch: 1: 49.88%\nTraining - Epoch: 2, Batch: 512, Loss: 1.5249\nTraining - Epoch: 2, Batch: 1024, Loss: 0.9221\nTraining Accuracy - Epoch: 2: 54.22%\nValidation Accuracy - Epoch: 2: 53.63%\nTraining - Epoch: 3, Batch: 512, Loss: 1.8045\nTraining - Epoch: 3, Batch: 1024, Loss: 1.9423\nTraining Accuracy - Epoch: 3: 58.74%\nValidation Accuracy - Epoch: 3: 56.42%\nTraining - Epoch: 4, Batch: 512, Loss: 0.8598\nTraining - Epoch: 4, Batch: 1024, Loss: 0.8330\nTraining Accuracy - Epoch: 4: 60.99%\nValidation Accuracy - Epoch: 4: 58.47%\nTraining - Epoch: 5, Batch: 512, Loss: 1.5801\nTraining - Epoch: 5, Batch: 1024, Loss: 1.3210\nTraining Accuracy - Epoch: 5: 63.78%\nValidation Accuracy - Epoch: 5: 58.11%\nTraining - Epoch: 6, Batch: 512, Loss: 0.9594\nTraining - Epoch: 6, Batch: 1024, Loss: 1.0034\nTraining Accuracy - Epoch: 6: 65.40%\nValidation Accuracy - Epoch: 6: 58.23%\nTraining - Epoch: 7, Batch: 512, Loss: 1.5709\nTraining - Epoch: 7, Batch: 1024, Loss: 1.1722\nTraining Accuracy - Epoch: 7: 68.45%\nValidation Accuracy - Epoch: 7: 61.14%\nTraining - Epoch: 8, Batch: 512, Loss: 0.4757\nTraining - Epoch: 8, Batch: 1024, Loss: 0.6685\nTraining Accuracy - Epoch: 8: 71.27%\nValidation Accuracy - Epoch: 8: 58.72%\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, params in enumerate(model.parameters()):\n        if i < 22:\n            params.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:44:21.899710Z","iopub.execute_input":"2024-02-18T09:44:21.900571Z","iopub.status.idle":"2024-02-18T09:44:21.905170Z","shell.execute_reply.started":"2024-02-18T09:44:21.900540Z","shell.execute_reply":"2024-02-18T09:44:21.904218Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"training(train_loader,val_loader,epochs = 8)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:44:38.364842Z","iopub.execute_input":"2024-02-18T09:44:38.365608Z","iopub.status.idle":"2024-02-18T09:49:55.272458Z","shell.execute_reply.started":"2024-02-18T09:44:38.365563Z","shell.execute_reply":"2024-02-18T09:49:55.271476Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Training - Epoch: 1, Batch: 512, Loss: 0.4473\nTraining - Epoch: 1, Batch: 1024, Loss: 0.3708\nTraining Accuracy - Epoch: 1: 67.24%\nValidation Accuracy - Epoch: 1: 59.93%\nTraining - Epoch: 2, Batch: 512, Loss: 0.2606\nTraining - Epoch: 2, Batch: 1024, Loss: 0.7515\nTraining Accuracy - Epoch: 2: 70.68%\nValidation Accuracy - Epoch: 2: 59.20%\nTraining - Epoch: 3, Batch: 512, Loss: 0.6003\nTraining - Epoch: 3, Batch: 1024, Loss: 0.3749\nTraining Accuracy - Epoch: 3: 73.05%\nValidation Accuracy - Epoch: 3: 60.77%\nTraining - Epoch: 4, Batch: 512, Loss: 0.9556\nTraining - Epoch: 4, Batch: 1024, Loss: 0.3401\nTraining Accuracy - Epoch: 4: 77.50%\nValidation Accuracy - Epoch: 4: 59.08%\nTraining - Epoch: 5, Batch: 512, Loss: 0.8115\nTraining - Epoch: 5, Batch: 1024, Loss: 0.2498\nTraining Accuracy - Epoch: 5: 80.74%\nValidation Accuracy - Epoch: 5: 56.17%\nTraining - Epoch: 6, Batch: 512, Loss: 0.0306\nTraining - Epoch: 6, Batch: 1024, Loss: 0.4931\nTraining Accuracy - Epoch: 6: 84.25%\nValidation Accuracy - Epoch: 6: 62.95%\nTraining - Epoch: 7, Batch: 512, Loss: 0.3007\nTraining - Epoch: 7, Batch: 1024, Loss: 0.2600\nTraining Accuracy - Epoch: 7: 87.26%\nValidation Accuracy - Epoch: 7: 59.56%\nTraining - Epoch: 8, Batch: 512, Loss: 0.0902\nTraining - Epoch: 8, Batch: 1024, Loss: 0.4161\nTraining Accuracy - Epoch: 8: 88.87%\nValidation Accuracy - Epoch: 8: 61.62%\n","output_type":"stream"}]},{"cell_type":"code","source":"testing(test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T09:50:01.784063Z","iopub.execute_input":"2024-02-18T09:50:01.784429Z","iopub.status.idle":"2024-02-18T09:50:05.304746Z","shell.execute_reply.started":"2024-02-18T09:50:01.784401Z","shell.execute_reply":"2024-02-18T09:50:05.303833Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Accuracy of the network on the 1656 test images:64.7947%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}